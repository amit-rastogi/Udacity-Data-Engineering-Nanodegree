Data Engineering Capstone Project

Project Summary
The project builds a data warehouse from the movielens dataset for the data analysts and machine learning engineers who could use the same to perform data analysis using OLAP cubes or build a movie recommendation system.

Scope
The Project's scope is to use the MovieLens dataset to create an ETL pipeline for creating a data warehouse in AWS Redshift.

Data Description
The project would be using the MovieLens 1M dataset which contains 1 million ratings from 6000 users on 4000 movies. Released in 2/2003.
The MovieLens dataset has been downloaded from https://grouplens.org/datasets/movielens/1m/.
The data are contained in the files movies.dat, ratings.dat and users.dat

Data Cleaning and Pre-processing
Cleaning

We would perform the the following cleaning steps for all the data files

check for missing values
check for duplicate values
Preprocessing

Preprocessing would consist of following 2 steps-

Add occupation column to users table with specific occupation names as per Readme of movielens_1m dataset to enrich the data for analyzing the movies data w.r.t various occupation.
Add age group column to users table with age group as per Readme of movielens_1m dataset to enrich the data for analyzing the movies data w.r.t various age groups.
The movielens dataset have :: as record delimiter. Since S3 copy command cannot handle more than one ascii character as delimiter hence we would write the pandas dataframes created above for movies, users and rating data to parquet format in S3. During ETL step we would use S3 copy to load the data from parquet files to staging tables.